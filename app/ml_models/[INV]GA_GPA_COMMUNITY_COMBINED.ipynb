{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TXO8o3GrC54I",
        "outputId": "c1492c2b-542a-469e-8083-e17e8e4716a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4168721-1724-4240-84f4-85c0208676cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4168721-1724-4240-84f4-85c0208676cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Student Survey - Jan.xlsx to Student Survey - Jan.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/Student Survey - Jan.xlsx\"  # Adjust if needed\n",
        "sheet_dict = pd.read_excel(file_path, sheet_name=None)  # Load all sheets into a dictionary\n",
        "\n",
        "# Access individual sheets\n",
        "df_affiliations = sheet_dict.get(\"affiliations\")\n",
        "df_participants = sheet_dict.get(\"participants\")\n",
        "df_responses = sheet_dict.get(\"responses\")\n",
        "df_friends = sheet_dict.get(\"net_0_Friends\")\n",
        "df_influential = sheet_dict.get(\"net_1_Influential\")\n",
        "df_feedback = sheet_dict.get(\"net_2_Feedback\")\n",
        "df_more_time = sheet_dict.get(\"net_3_MoreTime\")\n",
        "df_advice = sheet_dict.get(\"net_4_Advice\")\n",
        "df_disrespect = sheet_dict.get(\"net_5_Disrespect\")\n",
        "df_school_activity = sheet_dict.get(\"net_affiliation_0_SchoolActivit\")"
      ],
      "metadata": {
        "id": "W8-ZEuEzC6sc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx"
      ],
      "metadata": {
        "id": "gXbzHuHu-0H-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Community detection"
      ],
      "metadata": {
        "id": "22HMiDIGVQRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df_friends is already loaded\n",
        "# Remove self-loops (where Source == Target)\n",
        "df_disrespect = df_disrespect[df_disrespect[\"Source\"] != df_disrespect[\"Target\"]]\n",
        "\n",
        "# Create a directed graph (DiGraph)\n",
        "G = nx.DiGraph()\n",
        "for _, row in df_disrespect.iterrows():\n",
        "    G.add_edge(row[\"Source\"], row[\"Target\"])"
      ],
      "metadata": {
        "id": "q61nYRC4Dy1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-louvain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q47YQB-R66y0",
        "outputId": "8f9c7c42-9eb2-4ef4-bf3e-902ce19c0cba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.11/dist-packages (0.16)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from python-louvain) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-louvain) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfn8qt-sox_R",
        "outputId": "249c83a5-d896-4d79-bc9f-f9e0f909ace1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ca92Wlqc8a",
        "outputId": "742fa1a3-b170-4a67-e628-d1b164dc509e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def directed_modularity(G, communities):\n",
        "    \"\"\"\n",
        "    Compute directed modularity (Leicht-Newman) for a given partition.\n",
        "\n",
        "    Q = (1/m) * sum_{c in communities} sum_{i,j in c} [A_ij - (k_out(i) * k_in(j)) / m]\n",
        "\n",
        "    Parameters:\n",
        "      G: A NetworkX DiGraph.\n",
        "      communities: A list of sets, where each set contains the nodes in one community.\n",
        "\n",
        "    Returns:\n",
        "      Q: The modularity value.\n",
        "    \"\"\"\n",
        "    m = G.number_of_edges()\n",
        "    if m == 0:\n",
        "        return 0\n",
        "    Q = 0.0\n",
        "    for community in communities:\n",
        "        for i in community:\n",
        "            for j in community:\n",
        "                A_ij = 1 if G.has_edge(i, j) else 0\n",
        "                k_out_i = G.out_degree(i)\n",
        "                k_in_j = G.in_degree(j)\n",
        "                Q += (A_ij - (k_out_i * k_in_j) / m)\n",
        "    return Q / m\n",
        "\n",
        "def greedy_leicht_newman(G):\n",
        "    \"\"\"\n",
        "    A greedy algorithm to optimize directed modularity (Leicht-Newman method).\n",
        "\n",
        "    Starts with each node in its own community and iteratively merges the pair of communities\n",
        "    that yields the highest increase in directed modularity.\n",
        "\n",
        "    Parameters:\n",
        "      G: A NetworkX DiGraph.\n",
        "\n",
        "    Returns:\n",
        "      communities: A list of sets, each set is a community of nodes.\n",
        "    \"\"\"\n",
        "    # Initialize each node as its own community.\n",
        "    communities = [{node} for node in G.nodes()]\n",
        "    current_modularity = directed_modularity(G, communities)\n",
        "    print(\"Initial modularity:\", current_modularity)\n",
        "\n",
        "    improvement = True\n",
        "    while improvement:\n",
        "        improvement = False\n",
        "        best_delta = 0\n",
        "        best_pair = None\n",
        "\n",
        "        # Consider all pairs of communities.\n",
        "        for i in range(len(communities)):\n",
        "            for j in range(i + 1, len(communities)):\n",
        "                merged = communities[i] | communities[j]\n",
        "                # Form a new partition with communities[i] and communities[j] merged.\n",
        "                new_communities = [communities[k] for k in range(len(communities)) if k not in (i, j)]\n",
        "                new_communities.append(merged)\n",
        "                new_modularity = directed_modularity(G, new_communities)\n",
        "                delta = new_modularity - current_modularity\n",
        "                if delta > best_delta:\n",
        "                    best_delta = delta\n",
        "                    best_pair = (i, j, merged)\n",
        "\n",
        "        if best_pair is not None and best_delta > 0:\n",
        "            i, j, merged = best_pair\n",
        "            # Merge the best pair of communities.\n",
        "            communities = [communities[k] for k in range(len(communities)) if k not in (i, j)]\n",
        "            communities.append(merged)\n",
        "            current_modularity += best_delta\n",
        "            print(\"Merged communities, new modularity:\", current_modularity)\n",
        "            improvement = True\n",
        "\n",
        "    return communities\n",
        "\n",
        "# --- Use your existing graph G ---\n",
        "# Your graph G is already created from your df_friends data:\n",
        "# import networkx as nx\n",
        "# df_friends = df_friends[df_friends[\"Source\"] != df_friends[\"Target\"]]\n",
        "# G = nx.DiGraph()\n",
        "# for _, row in df_friends.iterrows():\n",
        "#     G.add_edge(row[\"Source\"], row[\"Target\"])\n",
        "\n",
        "# Run the greedy Leicht-Newman community detection algorithm on your graph\n",
        "final_communities = greedy_leicht_newman(G)\n",
        "\n",
        "# Print out the final communities\n",
        "print(\"\\nFinal communities:\")\n",
        "for idx, comm in enumerate(final_communities):\n",
        "    print(f\"Community {idx}: {sorted(comm)}\")"
      ],
      "metadata": {
        "id": "1BwcUrjI9qJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c19a391-b64b-4a9b-fc55-1657d80a3433"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial modularity: -0.005886426592797783\n",
            "Merged communities, new modularity: 0.007098337950138504\n",
            "Merged communities, new modularity: 0.02008310249307479\n",
            "Merged communities, new modularity: 0.03306786703601108\n",
            "Merged communities, new modularity: 0.046052631578947366\n",
            "Merged communities, new modularity: 0.05886426592797784\n",
            "Merged communities, new modularity: 0.07167590027700832\n",
            "Merged communities, new modularity: 0.0844875346260388\n",
            "Merged communities, new modularity: 0.09729916897506925\n",
            "Merged communities, new modularity: 0.11011080332409973\n",
            "Merged communities, new modularity: 0.12292243767313019\n",
            "Merged communities, new modularity: 0.13573407202216065\n",
            "Merged communities, new modularity: 0.1485457063711911\n",
            "Merged communities, new modularity: 0.16135734072022156\n",
            "Merged communities, new modularity: 0.174168975069252\n",
            "Merged communities, new modularity: 0.18680747922437665\n",
            "Merged communities, new modularity: 0.19944598337950134\n",
            "Merged communities, new modularity: 0.21191135734072017\n",
            "Merged communities, new modularity: 0.224376731301939\n",
            "Merged communities, new modularity: 0.2368421052631578\n",
            "Merged communities, new modularity: 0.24930747922437663\n",
            "Merged communities, new modularity: 0.26177285318559546\n",
            "Merged communities, new modularity: 0.27423822714681423\n",
            "Merged communities, new modularity: 0.28670360110803306\n",
            "Merged communities, new modularity: 0.2991689750692519\n",
            "Merged communities, new modularity: 0.3114612188365649\n",
            "Merged communities, new modularity: 0.323753462603878\n",
            "Merged communities, new modularity: 0.336045706371191\n",
            "Merged communities, new modularity: 0.3481648199445983\n",
            "Merged communities, new modularity: 0.3602839335180055\n",
            "Merged communities, new modularity: 0.37361495844875336\n",
            "Merged communities, new modularity: 0.3857340720221606\n",
            "Merged communities, new modularity: 0.39785318559556776\n",
            "Merged communities, new modularity: 0.4097991689750692\n",
            "Merged communities, new modularity: 0.42174515235457055\n",
            "Merged communities, new modularity: 0.4335180055401661\n",
            "Merged communities, new modularity: 0.44529085872576163\n",
            "Merged communities, new modularity: 0.45706371191135714\n",
            "Merged communities, new modularity: 0.46883656509695265\n",
            "Merged communities, new modularity: 0.4804362880886423\n",
            "Merged communities, new modularity: 0.4918628808864264\n",
            "Merged communities, new modularity: 0.5032894736842102\n",
            "Merged communities, new modularity: 0.5145429362880881\n",
            "Merged communities, new modularity: 0.5257963988919662\n",
            "Merged communities, new modularity: 0.5422437673130189\n",
            "Merged communities, new modularity: 0.5538434903047085\n",
            "Merged communities, new modularity: 0.5645775623268691\n",
            "Merged communities, new modularity: 0.5753116343490298\n",
            "Merged communities, new modularity: 0.5853531855955674\n",
            "Merged communities, new modularity: 0.5953947368421048\n",
            "Merged communities, new modularity: 0.6054362880886422\n",
            "Merged communities, new modularity: 0.6154778393351796\n",
            "Merged communities, new modularity: 0.625519390581717\n",
            "Merged communities, new modularity: 0.6353878116343485\n",
            "Merged communities, new modularity: 0.6450831024930742\n",
            "Merged communities, new modularity: 0.6525277008310237\n",
            "Merged communities, new modularity: 0.6594529085872564\n",
            "Merged communities, new modularity: 0.6646468144044313\n",
            "Merged communities, new modularity: 0.6691481994459826\n",
            "Merged communities, new modularity: 0.6734764542936279\n",
            "Merged communities, new modularity: 0.6760734072022144\n",
            "\n",
            "Final communities:\n",
            "Community 0: [np.int64(32524), np.int64(32536)]\n",
            "Community 1: [np.int64(32485), np.int64(32540)]\n",
            "Community 2: [np.int64(32414), np.int64(32426), np.int64(32503), np.int64(32521)]\n",
            "Community 3: [np.int64(32405), np.int64(32413), np.int64(32444), np.int64(32452), np.int64(32453), np.int64(32481)]\n",
            "Community 4: [np.int64(32402), np.int64(32421), np.int64(32422), np.int64(32476), np.int64(32522), np.int64(32529), np.int64(32545)]\n",
            "Community 5: [np.int64(32407), np.int64(32411), np.int64(32436), np.int64(32439), np.int64(32455), np.int64(32488), np.int64(32520), np.int64(32552)]\n",
            "Community 6: [np.int64(32406), np.int64(32428), np.int64(32443), np.int64(32448), np.int64(32459), np.int64(32460), np.int64(32464), np.int64(32466), np.int64(32473), np.int64(32484), np.int64(32491), np.int64(32498), np.int64(32526), np.int64(32544)]\n",
            "Community 7: [np.int64(32401), np.int64(32440), np.int64(32442), np.int64(32445), np.int64(32500), np.int64(32519), np.int64(32535), np.int64(32538), np.int64(32557), np.int64(32561)]\n",
            "Community 8: [np.int64(32393), np.int64(32415), np.int64(32425), np.int64(32441), np.int64(32449), np.int64(32451), np.int64(32457), np.int64(32472), np.int64(32482), np.int64(32490), np.int64(32547), np.int64(32556), np.int64(32559), np.int64(32560), np.int64(32564), np.int64(32565)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "# ---------- 1. Degree-based bully score  ----------\n",
        "def bully_score_degree(subg, weight=None):\n",
        "    in_d  = dict(subg.in_degree(weight=weight))   # # nominations received\n",
        "    out_d = dict(subg.out_degree(weight=weight))  # # nominations made\n",
        "    return {n: in_d[n] - out_d[n] for n in subg.nodes()}  # +ve ⇒ likely bully\n",
        "\n",
        "# ---------- 2. PageRank on the *reversed* graph ----------\n",
        "def bully_score_pagerank(subg, weight=None, alpha=0.85):\n",
        "    # Reverse edges so \"influential receivers\" of disrespect rank highest\n",
        "    return nx.pagerank(subg, alpha=alpha, weight=weight)\n",
        "\n",
        "# ---------- 3. Combine & pick top candidate ----------\n",
        "def combine_scores(deg_dict, pr_dict, w_deg=0.6, w_pr=0.4):\n",
        "    nodes = list(deg_dict.keys())\n",
        "    d_s   = minmax_scale([deg_dict[n] for n in nodes])\n",
        "    p_s   = minmax_scale([pr_dict[n]  for n in nodes])\n",
        "    return {n: w_deg*d_s[i] + w_pr*p_s[i] for i, n in enumerate(nodes)}\n",
        "\n",
        "def community_subgraphs(G, communities):\n",
        "    for cid, nodes in enumerate(communities):\n",
        "        yield cid, G.subgraph(nodes).copy()\n",
        "\n",
        "def bully_candidates(G_d, communities, weight=None):\n",
        "    results = {}\n",
        "    for cid, subg in community_subgraphs(G_d, communities):\n",
        "        deg_score = bully_score_degree(subg, weight)\n",
        "        pr_score  = bully_score_pagerank(subg, weight)\n",
        "        combo     = combine_scores(deg_score, pr_score)\n",
        "        bully     = max(combo, key=combo.get)              # top candidate\n",
        "        ranked    = sorted(combo.items(), key=lambda x: x[1], reverse=True)\n",
        "        results[cid] = {\"primary_bully\": bully, \"ranking\": ranked}\n",
        "    return results"
      ],
      "metadata": {
        "id": "T4g0T2yh8SDM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_info  = bully_candidates(G, final_communities)\n",
        "\n",
        "for cid, info in bully_info.items():\n",
        "    print(f\"Community {cid}: primary bully → {info['primary_bully']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX6_FE3HF6_Y",
        "outputId": "b1e3882b-3113-4982-e5eb-07b561cc5634"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Community 0: primary bully → 32536\n",
            "Community 1: primary bully → 32485\n",
            "Community 2: primary bully → 32414\n",
            "Community 3: primary bully → 32405\n",
            "Community 4: primary bully → 32422\n",
            "Community 5: primary bully → 32455\n",
            "Community 6: primary bully → 32466\n",
            "Community 7: primary bully → 32500\n",
            "Community 8: primary bully → 32441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# `final_communities` is a list of sets\n",
        "# `bully_info` is a dict: {community_id: {\"primary_bully\": ID}}\n",
        "\n",
        "# 1. Create a reverse lookup from student to their community\n",
        "student_to_community = {}\n",
        "for cid, members in enumerate(final_communities):\n",
        "    for student in members:\n",
        "        student_to_community[student] = cid\n",
        "\n",
        "# 2. Extract all bullies\n",
        "bully_dict = {}\n",
        "for cid, info in bully_info.items():\n",
        "    primary_bully = info[\"primary_bully\"]\n",
        "    victims = [sid for sid in final_communities[cid] if sid != primary_bully]\n",
        "    bully_dict[primary_bully] = victims\n",
        "\n",
        "# 3. Victim subgraph (exclude all known bullies)\n",
        "all_victims = {sid for comm in final_communities for sid in comm}\n",
        "all_bullies = set(bully_dict.keys())\n",
        "victim_nodes = all_victims - all_bullies\n",
        "\n",
        "victim_graph = G.subgraph(victim_nodes).copy()"
      ],
      "metadata": {
        "id": "X7xzn2Uhn82l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPA Regression"
      ],
      "metadata": {
        "id": "o9EkXNxAoG_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import HeteroConv, GATConv\n",
        "from pathlib import Path\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 1. Load workbook & node table\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "file_path = \"/content/Student Survey - Jan.xlsx\"\n",
        "sheets = pd.read_excel(file_path, sheet_name=None)\n",
        "df_nodes = (sheets[\"participants\"]\n",
        "            .merge(sheets[\"responses\"], on=\"Participant-ID\", how=\"left\",\n",
        "                   suffixes=(\"\", \"_resp\")))\n",
        "df_nodes = df_nodes.dropna(subset=[\"Perc_Academic\"])      # keep only labelled\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 2. Tabular preprocessing ➜ numpy feature matrix\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "# 2-a.  Label-aware normalisation  (z-score within House)\n",
        "df_nodes[\"House\"] = df_nodes[\"House\"].astype(\"category\")\n",
        "mu  = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"mean\")\n",
        "std = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"std\").clip(lower=1e-6)\n",
        "y_raw = df_nodes[\"Perc_Academic\"].to_numpy(dtype=\"float32\")        # keep raw\n",
        "y     = ((y_raw - mu) / std).to_numpy(dtype=\"float32\")             # scaled\n",
        "\n",
        "# 2-b.  *now* drop the target so it isn’t used as an input feature\n",
        "df_nodes = df_nodes.drop(columns=[\"Perc_Academic\"])\n",
        "df_nodes = df_nodes.dropna(axis=1, how=\"all\")             # drop empty columns\n",
        "\n",
        "num_cols = df_nodes.select_dtypes([\"int64\", \"float64\"]).columns\n",
        "cat_cols = df_nodes.select_dtypes([\"object\", \"category\", \"bool\"]).columns\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"std\", StandardScaler())\n",
        "    ]), num_cols),\n",
        "\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        # ↓ set sparse_output=False (sklearn ≥1.2) or sparse=False (≤1.1)\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "    ]), cat_cols)\n",
        "])\n",
        "\n",
        "X = pre.fit_transform(df_nodes).astype(\"float32\")   # now a NumPy ndarray\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 3. Build HeteroData with **six relations + reverse edges**\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "pid_arr = df_nodes[\"Participant-ID\"].to_numpy()\n",
        "pid2idx = {pid: i for i, pid in enumerate(pid_arr)}\n",
        "\n",
        "data = HeteroData()\n",
        "data[\"student\"].x = torch.from_numpy(X)\n",
        "data[\"student\"].y = torch.from_numpy(y)\n",
        "\n",
        "edge_sheets = {\n",
        "    \"friends\"     : \"net_0_Friends\",\n",
        "    \"influential\" : \"net_1_Influential\",\n",
        "    \"feedback\"    : \"net_2_Feedback\",\n",
        "    \"moretime\"    : \"net_3_MoreTime\",\n",
        "    \"advice\"      : \"net_4_Advice\",\n",
        "    \"disrespect\"  : \"net_5_Disrespect\"\n",
        "}\n",
        "\n",
        "for rel, sheet_name in edge_sheets.items():\n",
        "    df_e = sheets[sheet_name][[\"Source\", \"Target\"]].dropna()\n",
        "    mask = df_e[\"Source\"].isin(pid2idx) & df_e[\"Target\"].isin(pid2idx)\n",
        "    src = df_e.loc[mask, \"Source\"].map(pid2idx).to_numpy()\n",
        "    dst = df_e.loc[mask, \"Target\"].map(pid2idx).to_numpy()\n",
        "    if len(src) == 0:             # skip empty relations\n",
        "        continue\n",
        "    ei = torch.tensor([src, dst], dtype=torch.long)\n",
        "    data[\"student\", rel, \"student\"].edge_index = ei\n",
        "    # add explicit reverse relation to aid message flow\n",
        "    data[\"student\", f\"{rel}_rev\", \"student\"].edge_index = ei.flip(0)\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 4. Masks\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "seed = 42\n",
        "bins = pd.qcut(y, q=4, labels=False, duplicates=\"drop\")\n",
        "sss  = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=seed)\n",
        "train_idx, tmp_idx = next(sss.split(np.arange(len(y)), bins))\n",
        "\n",
        "# split the remaining 30 % in half (stratified)\n",
        "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
        "val_idx, test_idx = next(sss2.split(tmp_idx, bins[tmp_idx]))\n",
        "\n",
        "# build boolean masks\n",
        "for name, idx_arr in [(\"train_mask\", train_idx),\n",
        "                      (\"val_mask\",   val_idx),\n",
        "                      (\"test_mask\",  test_idx)]:\n",
        "    mask = torch.zeros(data[\"student\"].num_nodes, dtype=torch.bool)\n",
        "    mask[idx_arr] = True\n",
        "    data[\"student\"][name] = mask\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 5. 2-layer Relational GAT\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RGAT(torch.nn.Module):\n",
        "    def __init__(self, metadata, in_dim, hid=64, heads=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.lin_in = torch.nn.Linear(in_dim, hid)\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(2):\n",
        "            conv_dict = {\n",
        "                et: GATConv(\n",
        "                    (-1, -1),\n",
        "                    32,\n",
        "                    heads=heads,\n",
        "                    concat=True,\n",
        "                    dropout=0.2,\n",
        "                    add_self_loops=False         # ← keep this\n",
        "                    # edge_dropout=0.2  ← remove / comment out\n",
        "                    )\n",
        "                for et in metadata[1]\n",
        "}\n",
        "            self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "\n",
        "        self.lin_out = torch.nn.Linear(32 * heads, 1)   # 32×3 → 1\n",
        "        self.dp = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x_dict = {\"student\": torch.relu(self.lin_in(data[\"student\"].x))}\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, data.edge_index_dict)\n",
        "            x_dict = {k: torch.relu(v) for k, v in x_dict.items()}\n",
        "            x_dict = {k: self.dp(v)    for k, v in x_dict.items()}\n",
        "        return self.lin_out(x_dict[\"student\"]).squeeze()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RGAT(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "data = data.to(device)\n",
        "opt  = torch.optim.Adam(model.parameters(), lr=1.0e-3, weight_decay=5e-4)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "#  (everything up to HeteroData stays the same, except use y not y_raw)\n",
        "\n",
        "# ===================================================================\n",
        "#  B.  tiny grid search: depth ∈ {2,3}, heads ∈ {2–6}, dropout ∈ {0–0.4}\n",
        "# ===================================================================\n",
        "hyper_grid = {\n",
        "    \"depth\":   [2, 3],\n",
        "    \"heads\":   [2, 3, 4, 5, 6],\n",
        "    \"dropout\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "}\n",
        "best_val = float(\"inf\")\n",
        "best_cfg, best_state = None, None\n",
        "\n",
        "for depth in hyper_grid[\"depth\"]:\n",
        "    for heads in hyper_grid[\"heads\"]:\n",
        "        for dp in hyper_grid[\"dropout\"]:\n",
        "            torch.manual_seed(seed)           # reproducible per run\n",
        "            np.random.seed(seed)\n",
        "\n",
        "            # -- define RGAT with variable depth / heads / dropout ----\n",
        "            class RGAT(torch.nn.Module):\n",
        "                def __init__(self, metadata, in_dim):\n",
        "                    super().__init__()\n",
        "                    self.lin_in = torch.nn.Linear(in_dim, 64)\n",
        "                    self.convs = torch.nn.ModuleList()\n",
        "                    for _ in range(depth):\n",
        "                        conv_dict = {\n",
        "                            et: GATConv((-1, -1), 32,\n",
        "                                        heads=heads, concat=True,\n",
        "                                        dropout=dp, add_self_loops=False)\n",
        "                            for et in metadata[1]\n",
        "                        }\n",
        "                        self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "                    self.lin_out = torch.nn.Linear(32 * heads, 1)\n",
        "                    self.dp = torch.nn.Dropout(dp)\n",
        "\n",
        "                def forward(self, d):\n",
        "                    x = {\"student\": torch.relu(self.lin_in(d[\"student\"].x))}\n",
        "                    for conv in self.convs:\n",
        "                        x = conv(x, d.edge_index_dict)\n",
        "                        x = {k: torch.relu(v) for k, v in x.items()}\n",
        "                        x = {k: self.dp(v)    for k, v in x.items()}\n",
        "                    return self.lin_out(x[\"student\"]).squeeze()\n",
        "\n",
        "            model = RGAT(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "            opt   = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "            sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\",\n",
        "                                                               factor=0.5, patience=10)\n",
        "            best_rmse, wait = float(\"inf\"), 0\n",
        "            for epoch in range(1, 401):\n",
        "                model.train(); opt.zero_grad()\n",
        "                out  = model(data)\n",
        "                loss = loss_fn(out[data[\"student\"].train_mask],\n",
        "                               data[\"student\"].y[data[\"student\"].train_mask])\n",
        "                loss.backward(); opt.step()\n",
        "\n",
        "                # validation\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    v_pred = model(data)[data[\"student\"].val_mask].cpu()\n",
        "                v_rmse = np.sqrt(mean_squared_error(\n",
        "                    data[\"student\"].y[data[\"student\"].val_mask].cpu(), v_pred))\n",
        "                sched.step(v_rmse)\n",
        "\n",
        "                if v_rmse + 1e-3 < best_rmse:\n",
        "                    best_rmse, wait = v_rmse, 0\n",
        "                    best_state = model.state_dict()\n",
        "                else:\n",
        "                    wait += 1\n",
        "                if wait >= 30:               # early stop\n",
        "                    break\n",
        "\n",
        "            # keep global best\n",
        "            if best_rmse < best_val:\n",
        "                best_val, best_cfg = best_rmse, (depth, heads, dp)\n",
        "                torch.save(best_state, \"rgat_best_overall.pt\")\n",
        "\n",
        "print(f\"Best config depth={best_cfg[0]} heads={best_cfg[1]} dropout={best_cfg[2]:.1f}\"\n",
        "      f\"  |  val-RMSE={best_val:5.2f}\")\n",
        "\n",
        "# ===================================================================\n",
        "#  C.  final test metrics on best model\n",
        "# ===================================================================\n",
        "# ── rebuild model with the winning hyper-params ─────────────────────\n",
        "best_depth, best_heads, best_dp = best_cfg\n",
        "class RGAT_Best(torch.nn.Module):\n",
        "    def __init__(self, metadata, in_dim):\n",
        "        super().__init__()\n",
        "        self.lin_in = torch.nn.Linear(in_dim, 64)\n",
        "        self.convs  = torch.nn.ModuleList()\n",
        "        for _ in range(best_depth):\n",
        "            conv_dict = {\n",
        "                et: GATConv((-1, -1), 32,\n",
        "                            heads=best_heads, concat=True,\n",
        "                            dropout=best_dp, add_self_loops=False)\n",
        "                for et in metadata[1]\n",
        "            }\n",
        "            self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "        self.lin_out = torch.nn.Linear(32 * best_heads, 1)\n",
        "        self.dp = torch.nn.Dropout(best_dp)\n",
        "\n",
        "    def forward(self, d):\n",
        "        x = {\"student\": torch.relu(self.lin_in(d[\"student\"].x))}\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, d.edge_index_dict)\n",
        "            x = {k: torch.relu(v) for k, v in x.items()}\n",
        "            x = {k: self.dp(v)    for k, v in x.items()}\n",
        "        return self.lin_out(x[\"student\"]).squeeze()\n",
        "\n",
        "model = RGAT_Best(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "model.load_state_dict(torch.load(\"rgat_best_overall.pt\"), strict=False)\n",
        "model.eval()\n",
        "\n",
        "# ── test inference ───────────────────────────────────────────────────\n",
        "with torch.no_grad():\n",
        "    y_hat_scaled = model(data).cpu().numpy()\n",
        "\n",
        "# un-scale back to raw GPA units\n",
        "y_hat = y_hat_scaled * std.to_numpy() + mu.to_numpy()\n",
        "\n",
        "test_mask = data[\"student\"].test_mask.cpu().numpy()\n",
        "mae  = mean_absolute_error(y_raw[test_mask], y_hat[test_mask])\n",
        "rmse = np.sqrt(mean_squared_error(y_raw[test_mask], y_hat[test_mask]))\n",
        "r2   = r2_score(y_raw[test_mask], y_hat[test_mask])\n",
        "\n",
        "print(\"\\n=== RGAT  (grid-tuned, label-normalised) ===\")\n",
        "print(f\"MAE : {mae:5.2f}\")\n",
        "print(f\"RMSE: {rmse:5.2f}\")\n",
        "print(f\"R²  : {r2:5.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi5sHvmQHouM",
        "outputId": "68ac2a65-930e-42dd-99a1-24782fd32249"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b763de18607f>:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  mu  = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"mean\")\n",
            "<ipython-input-12-b763de18607f>:28: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  std = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"std\").clip(lower=1e-6)\n",
            "<ipython-input-12-b763de18607f>:80: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  ei = torch.tensor([src, dst], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best config depth=2 heads=2 dropout=0.0  |  val-RMSE= 0.52\n",
            "\n",
            "=== RGAT  (grid-tuned, label-normalised) ===\n",
            "MAE :  2.35\n",
            "RMSE:  7.81\n",
            "R²  :  0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After model inference and unscaling\n",
        "with torch.no_grad():\n",
        "    y_hat_scaled = model(data).cpu().numpy()\n",
        "\n",
        "# Unscale back to raw GPA\n",
        "y_hat = y_hat_scaled * std.to_numpy() + mu.to_numpy()\n",
        "\n",
        "# Build GPA prediction dict\n",
        "predicted_gpa_dict = {\n",
        "    pid: float(gpa) for pid, gpa in zip(df_nodes[\"Participant-ID\"], y_hat)\n",
        "}"
      ],
      "metadata": {
        "id": "ZraLRt4Dn2zG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpa_bins = pd.qcut(list(predicted_gpa_dict.values()), q=4, labels=False)\n",
        "gpa_bin_dict = {sid: gpa_bins[i] for i, sid in enumerate(predicted_gpa_dict)}\n",
        "global_bin_counts = np.bincount(gpa_bins, minlength=4)\n",
        "global_bin_dist = global_bin_counts / global_bin_counts.sum()"
      ],
      "metadata": {
        "id": "rYu9K-sCuW-q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GA"
      ],
      "metadata": {
        "id": "bmcyDWTXoPJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# === Configuration ===\n",
        "num_classes = 6\n",
        "MAX_SIZE = 30\n",
        "MAX_DIFF = 3\n",
        "student_ids = list(predicted_gpa_dict.keys())\n",
        "\n",
        "# === GPA Binning Preprocessing ===\n",
        "gpa_series = pd.Series(predicted_gpa_dict)\n",
        "gpa_bins = pd.qcut(gpa_series, q=4, labels=False, duplicates=\"drop\")  # Quartiles\n",
        "gpa_bin_dict = gpa_bins.to_dict()\n",
        "global_bin_counts = np.bincount(gpa_bins, minlength=4)\n",
        "global_bin_dist = global_bin_counts / global_bin_counts.sum()\n",
        "\n",
        "# === DEAP Setup ===\n",
        "try:\n",
        "    creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0, -1.0, -1.0))  # All minimized\n",
        "    creator.create(\"Individual\", dict, fitness=creator.FitnessMulti)\n",
        "except:\n",
        "    pass  # Ignore if already created\n",
        "\n",
        "# === Flexible Repair Function ===\n",
        "def flexible_repair(individual, max_size=MAX_SIZE, max_diff=MAX_DIFF):\n",
        "    class_counts = {i: 0 for i in range(num_classes)}\n",
        "    class_to_students = {i: [] for i in range(num_classes)}\n",
        "    for sid, cid in individual.items():\n",
        "        class_counts[cid] += 1\n",
        "        class_to_students[cid].append(sid)\n",
        "\n",
        "    for cid in range(num_classes):\n",
        "        while class_counts[cid] > max_size:\n",
        "            sid = random.choice(class_to_students[cid])\n",
        "            for target in range(num_classes):\n",
        "                if class_counts[target] < max_size:\n",
        "                    individual[sid] = target\n",
        "                    class_counts[cid] -= 1\n",
        "                    class_counts[target] += 1\n",
        "                    class_to_students[cid].remove(sid)\n",
        "                    class_to_students[target].append(sid)\n",
        "                    break\n",
        "\n",
        "    def get_max_min_class():\n",
        "        counts = sorted(class_counts.items(), key=lambda x: x[1])\n",
        "        return counts[-1][0], counts[0][0]\n",
        "\n",
        "    max_c, min_c = get_max_min_class()\n",
        "    while class_counts[max_c] - class_counts[min_c] > max_diff:\n",
        "        sid = random.choice(class_to_students[max_c])\n",
        "        individual[sid] = min_c\n",
        "        class_counts[max_c] -= 1\n",
        "        class_counts[min_c] += 1\n",
        "        class_to_students[max_c].remove(sid)\n",
        "        class_to_students[min_c].append(sid)\n",
        "        max_c, min_c = get_max_min_class()\n",
        "\n",
        "    return individual\n",
        "\n",
        "# === Random Allocation ===\n",
        "def random_allocation():\n",
        "    shuffled = student_ids[:]\n",
        "    random.shuffle(shuffled)\n",
        "    individual = {}\n",
        "    class_sizes = [0] * num_classes\n",
        "    for sid in shuffled:\n",
        "        for cid in range(num_classes):\n",
        "            if class_sizes[cid] < MAX_SIZE:\n",
        "                individual[sid] = cid\n",
        "                class_sizes[cid] += 1\n",
        "                break\n",
        "    return creator.Individual(flexible_repair(individual))\n",
        "\n",
        "# === Fitness Function (with bin objective) ===\n",
        "def calculate_multi_objective_fitness(individual):\n",
        "    class_gpas = {i: [] for i in range(num_classes)}\n",
        "    class_bins = {i: np.zeros(4) for i in range(num_classes)}\n",
        "\n",
        "    for sid, cid in individual.items():\n",
        "        class_gpas[cid].append(predicted_gpa_dict.get(sid, 0))\n",
        "        bin_idx = gpa_bin_dict.get(sid)\n",
        "        if bin_idx is not None:\n",
        "            class_bins[cid][bin_idx] += 1\n",
        "\n",
        "    gpa_std = np.std([np.mean(v) for v in class_gpas.values() if v])\n",
        "\n",
        "    dist_penalty = 0\n",
        "    for cid in range(num_classes):\n",
        "        total = class_bins[cid].sum()\n",
        "        if total > 0:\n",
        "            class_bins[cid] /= total\n",
        "            dist_penalty += np.sum((class_bins[cid] - global_bin_dist) ** 2)\n",
        "\n",
        "    bv_conflict = sum(\n",
        "        1 for bully, victims in bully_dict.items()\n",
        "        for v in victims\n",
        "        if bully in individual and v in individual and individual[bully] == individual[v]\n",
        "    )\n",
        "\n",
        "    vv_edges = sum(\n",
        "        1 for u, v in victim_graph.edges()\n",
        "        if u in individual and v in individual and individual[u] == individual[v]\n",
        "    )\n",
        "\n",
        "    return gpa_std, bv_conflict, vv_edges, dist_penalty\n",
        "\n",
        "# === Genetic Operators ===\n",
        "def mutate(ind):\n",
        "    sid = random.choice(list(ind.keys()))\n",
        "    ind[sid] = random.randint(0, num_classes - 1)\n",
        "    flexible_repair(ind)\n",
        "    ind.fitness.values = calculate_multi_objective_fitness(ind)\n",
        "    return ind,\n",
        "\n",
        "def crossover(ind1, ind2):\n",
        "    keys = list(ind1.keys())\n",
        "    point = random.randint(1, len(keys) - 1)\n",
        "    for k in keys[point:]:\n",
        "        ind1[k], ind2[k] = ind2[k], ind1[k]\n",
        "    flexible_repair(ind1)\n",
        "    flexible_repair(ind2)\n",
        "    ind1.fitness.values = calculate_multi_objective_fitness(ind1)\n",
        "    ind2.fitness.values = calculate_multi_objective_fitness(ind2)\n",
        "    return ind1, ind2\n",
        "\n",
        "# === Toolbox ===\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"individual\", random_allocation)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"mate\", crossover)\n",
        "toolbox.register(\"mutate\", mutate)\n",
        "toolbox.register(\"select\", tools.selNSGA2)\n",
        "toolbox.register(\"evaluate\", calculate_multi_objective_fitness)\n",
        "\n",
        "# === Run GA ===\n",
        "population = toolbox.population(n=100)\n",
        "for ind in population:\n",
        "    ind.fitness.values = calculate_multi_objective_fitness(ind)\n",
        "\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=50,\n",
        "                    stats=None, halloffame=None, verbose=True)\n",
        "\n",
        "# === Output Best ===\n",
        "best_individual = tools.selBest(population, 1)[0]\n",
        "print(\"\\n✅ Best allocation found:\")\n",
        "print(best_individual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBpNLbfcYKIe",
        "outputId": "4be8cb93-03d8-481f-b9f2-eb7ad8a1b5cc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen\tnevals\n",
            "0  \t0     \n",
            "1  \t76    \n",
            "2  \t76    \n",
            "3  \t76    \n",
            "4  \t69    \n",
            "5  \t80    \n",
            "6  \t78    \n",
            "7  \t77    \n",
            "8  \t75    \n",
            "9  \t75    \n",
            "10 \t81    \n",
            "11 \t77    \n",
            "12 \t72    \n",
            "13 \t81    \n",
            "14 \t68    \n",
            "15 \t71    \n",
            "16 \t70    \n",
            "17 \t67    \n",
            "18 \t62    \n",
            "19 \t62    \n",
            "20 \t68    \n",
            "21 \t76    \n",
            "22 \t80    \n",
            "23 \t83    \n",
            "24 \t84    \n",
            "25 \t72    \n",
            "26 \t76    \n",
            "27 \t85    \n",
            "28 \t70    \n",
            "29 \t82    \n",
            "30 \t83    \n",
            "31 \t81    \n",
            "32 \t81    \n",
            "33 \t74    \n",
            "34 \t84    \n",
            "35 \t88    \n",
            "36 \t78    \n",
            "37 \t75    \n",
            "38 \t68    \n",
            "39 \t77    \n",
            "40 \t75    \n",
            "41 \t78    \n",
            "42 \t76    \n",
            "43 \t84    \n",
            "44 \t78    \n",
            "45 \t72    \n",
            "46 \t84    \n",
            "47 \t75    \n",
            "48 \t80    \n",
            "49 \t80    \n",
            "50 \t76    \n",
            "\n",
            "✅ Best allocation found:\n",
            "{32409: 3, 32427: 1, 32407: 2, 32551: 5, 32452: 0, 32391: 1, 32419: 2, 32415: 1, 32520: 2, 32394: 0, 32484: 3, 32473: 0, 32446: 2, 32560: 3, 32512: 3, 32493: 4, 32537: 5, 32451: 0, 32563: 4, 32508: 3, 32561: 2, 32532: 1, 32544: 4, 32499: 1, 32526: 0, 32494: 1, 32468: 1, 32519: 4, 32505: 5, 32408: 3, 32514: 2, 32502: 0, 32423: 1, 32509: 4, 32430: 3, 32433: 1, 32428: 0, 32533: 2, 32515: 3, 32524: 0, 32527: 4, 32469: 5, 32463: 5, 32500: 0, 32541: 4, 32421: 2, 32498: 1, 32547: 1, 32438: 0, 32497: 3, 32554: 5, 32477: 4, 32470: 3, 32481: 4, 32431: 5, 32404: 1, 32555: 5, 32414: 2, 32495: 2, 32466: 1, 32399: 1, 32513: 3, 32429: 4, 32462: 0, 32406: 2, 32432: 4, 32486: 1, 32422: 5, 32525: 1, 32413: 3, 32483: 5, 32548: 3, 32401: 1, 32488: 0, 32540: 2, 32437: 5, 32393: 5, 32402: 2, 32475: 1, 32425: 4, 32562: 5, 32490: 3, 32439: 1, 32417: 4, 32474: 3, 32536: 2, 32507: 0, 32457: 3, 32435: 0, 32480: 0, 32542: 0, 32565: 0, 32459: 2, 32398: 4, 32418: 3, 32395: 0, 32426: 0, 32482: 4, 32538: 0, 32558: 4, 32517: 4, 32556: 0, 32550: 4, 32392: 2, 32485: 1, 32516: 0, 32453: 2, 32455: 2, 32476: 0, 32448: 5, 32454: 4, 32478: 3, 32521: 4, 32442: 5, 32506: 3, 32441: 5, 32489: 4, 32411: 3, 32492: 5, 32534: 1, 32504: 1, 32496: 3, 32510: 5, 32546: 4, 32458: 3, 32403: 3, 32529: 2, 32397: 5, 32501: 3, 32436: 4, 32471: 2, 32539: 5, 32445: 5, 32464: 2, 32461: 1, 32467: 1, 32396: 4, 32487: 1, 32450: 2, 32420: 4, 32511: 4, 32530: 3, 32444: 1, 32440: 2, 32522: 0, 32472: 4, 32531: 4, 32456: 5, 32549: 2, 32416: 5, 32557: 3, 32559: 2, 32410: 4, 32449: 1, 32400: 0, 32523: 3, 32412: 0, 32545: 2, 32405: 3, 32479: 0, 32553: 2, 32543: 1, 32447: 0, 32528: 5, 32443: 5, 32491: 5, 32434: 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1wTIERqq0MY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}