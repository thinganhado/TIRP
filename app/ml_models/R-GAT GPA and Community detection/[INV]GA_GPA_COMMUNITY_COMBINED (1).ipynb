{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/Student Survey - Jan.xlsx\"  # Adjust if needed\n",
        "sheet_dict = pd.read_excel(file_path, sheet_name=None)  # Load all sheets into a dictionary\n",
        "\n",
        "# Access individual sheets\n",
        "df_affiliations = sheet_dict.get(\"affiliations\")\n",
        "df_participants = sheet_dict.get(\"participants\")\n",
        "df_responses = sheet_dict.get(\"responses\")\n",
        "df_friends = sheet_dict.get(\"net_0_Friends\")\n",
        "df_influential = sheet_dict.get(\"net_1_Influential\")\n",
        "df_feedback = sheet_dict.get(\"net_2_Feedback\")\n",
        "df_more_time = sheet_dict.get(\"net_3_MoreTime\")\n",
        "df_advice = sheet_dict.get(\"net_4_Advice\")\n",
        "df_disrespect = sheet_dict.get(\"net_5_Disrespect\")\n",
        "df_school_activity = sheet_dict.get(\"net_affiliation_0_SchoolActivit\")"
      ],
      "metadata": {
        "id": "W8-ZEuEzC6sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx"
      ],
      "metadata": {
        "id": "gXbzHuHu-0H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Community detection"
      ],
      "metadata": {
        "id": "22HMiDIGVQRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove self-loops (where Source == Target)\n",
        "df_disrespect = df_disrespect[df_disrespect[\"Source\"] != df_disrespect[\"Target\"]]\n",
        "\n",
        "# Create a directed graph (DiGraph)\n",
        "G = nx.DiGraph()\n",
        "for _, row in df_disrespect.iterrows():\n",
        "    G.add_edge(row[\"Source\"], row[\"Target\"])"
      ],
      "metadata": {
        "id": "q61nYRC4Dy1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-louvain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q47YQB-R66y0",
        "outputId": "8f9c7c42-9eb2-4ef4-bf3e-902ce19c0cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.11/dist-packages (0.16)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from python-louvain) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-louvain) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfn8qt-sox_R",
        "outputId": "249c83a5-d896-4d79-bc9f-f9e0f909ace1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ca92Wlqc8a",
        "outputId": "742fa1a3-b170-4a67-e628-d1b164dc509e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def directed_modularity(G, communities):\n",
        "    \"\"\"\n",
        "    Compute directed modularity (Leicht-Newman) for a given partition.\n",
        "\n",
        "    Q = (1/m) * sum_{c in communities} sum_{i,j in c} [A_ij - (k_out(i) * k_in(j)) / m]\n",
        "\n",
        "    Parameters:\n",
        "      G: A NetworkX DiGraph.\n",
        "      communities: A list of sets, where each set contains the nodes in one community.\n",
        "\n",
        "    Returns:\n",
        "      Q: The modularity value.\n",
        "    \"\"\"\n",
        "    m = G.number_of_edges()\n",
        "    if m == 0:\n",
        "        return 0\n",
        "    Q = 0.0\n",
        "    for community in communities:\n",
        "        for i in community:\n",
        "            for j in community:\n",
        "                A_ij = 1 if G.has_edge(i, j) else 0\n",
        "                k_out_i = G.out_degree(i)\n",
        "                k_in_j = G.in_degree(j)\n",
        "                Q += (A_ij - (k_out_i * k_in_j) / m)\n",
        "    return Q / m\n",
        "\n",
        "def greedy_leicht_newman(G):\n",
        "    \"\"\"\n",
        "    A greedy algorithm to optimize directed modularity (Leicht-Newman method).\n",
        "\n",
        "    Starts with each node in its own community and iteratively merges the pair of communities\n",
        "    that yields the highest increase in directed modularity.\n",
        "\n",
        "    Parameters:\n",
        "      G: A NetworkX DiGraph.\n",
        "\n",
        "    Returns:\n",
        "      communities: A list of sets, each set is a community of nodes.\n",
        "    \"\"\"\n",
        "    # Initialize each node as its own community.\n",
        "    communities = [{node} for node in G.nodes()]\n",
        "    current_modularity = directed_modularity(G, communities)\n",
        "    print(\"Initial modularity:\", current_modularity)\n",
        "\n",
        "    improvement = True\n",
        "    while improvement:\n",
        "        improvement = False\n",
        "        best_delta = 0\n",
        "        best_pair = None\n",
        "\n",
        "        # Consider all pairs of communities.\n",
        "        for i in range(len(communities)):\n",
        "            for j in range(i + 1, len(communities)):\n",
        "                merged = communities[i] | communities[j]\n",
        "                # Form a new partition with communities[i] and communities[j] merged.\n",
        "                new_communities = [communities[k] for k in range(len(communities)) if k not in (i, j)]\n",
        "                new_communities.append(merged)\n",
        "                new_modularity = directed_modularity(G, new_communities)\n",
        "                delta = new_modularity - current_modularity\n",
        "                if delta > best_delta:\n",
        "                    best_delta = delta\n",
        "                    best_pair = (i, j, merged)\n",
        "\n",
        "        if best_pair is not None and best_delta > 0:\n",
        "            i, j, merged = best_pair\n",
        "            # Merge the best pair of communities.\n",
        "            communities = [communities[k] for k in range(len(communities)) if k not in (i, j)]\n",
        "            communities.append(merged)\n",
        "            current_modularity += best_delta\n",
        "            print(\"Merged communities, new modularity:\", current_modularity)\n",
        "            improvement = True\n",
        "\n",
        "    return communities\n",
        "\n",
        "# Run the greedy Leicht-Newman community detection algorithm on your graph\n",
        "final_communities = greedy_leicht_newman(G)\n",
        "\n",
        "# Print out the final communities\n",
        "print(\"\\nFinal communities:\")\n",
        "for idx, comm in enumerate(final_communities):\n",
        "    print(f\"Community {idx}: {sorted(comm)}\")"
      ],
      "metadata": {
        "id": "1BwcUrjI9qJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c19a391-b64b-4a9b-fc55-1657d80a3433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial modularity: -0.005886426592797783\n",
            "Merged communities, new modularity: 0.007098337950138504\n",
            "Merged communities, new modularity: 0.02008310249307479\n",
            "Merged communities, new modularity: 0.03306786703601108\n",
            "Merged communities, new modularity: 0.046052631578947366\n",
            "Merged communities, new modularity: 0.05886426592797784\n",
            "Merged communities, new modularity: 0.07167590027700832\n",
            "Merged communities, new modularity: 0.0844875346260388\n",
            "Merged communities, new modularity: 0.09729916897506925\n",
            "Merged communities, new modularity: 0.11011080332409973\n",
            "Merged communities, new modularity: 0.12292243767313019\n",
            "Merged communities, new modularity: 0.13573407202216065\n",
            "Merged communities, new modularity: 0.1485457063711911\n",
            "Merged communities, new modularity: 0.16135734072022156\n",
            "Merged communities, new modularity: 0.174168975069252\n",
            "Merged communities, new modularity: 0.18680747922437665\n",
            "Merged communities, new modularity: 0.19944598337950134\n",
            "Merged communities, new modularity: 0.21191135734072017\n",
            "Merged communities, new modularity: 0.224376731301939\n",
            "Merged communities, new modularity: 0.2368421052631578\n",
            "Merged communities, new modularity: 0.24930747922437663\n",
            "Merged communities, new modularity: 0.26177285318559546\n",
            "Merged communities, new modularity: 0.27423822714681423\n",
            "Merged communities, new modularity: 0.28670360110803306\n",
            "Merged communities, new modularity: 0.2991689750692519\n",
            "Merged communities, new modularity: 0.3114612188365649\n",
            "Merged communities, new modularity: 0.323753462603878\n",
            "Merged communities, new modularity: 0.336045706371191\n",
            "Merged communities, new modularity: 0.3481648199445983\n",
            "Merged communities, new modularity: 0.3602839335180055\n",
            "Merged communities, new modularity: 0.37361495844875336\n",
            "Merged communities, new modularity: 0.3857340720221606\n",
            "Merged communities, new modularity: 0.39785318559556776\n",
            "Merged communities, new modularity: 0.4097991689750692\n",
            "Merged communities, new modularity: 0.42174515235457055\n",
            "Merged communities, new modularity: 0.4335180055401661\n",
            "Merged communities, new modularity: 0.44529085872576163\n",
            "Merged communities, new modularity: 0.45706371191135714\n",
            "Merged communities, new modularity: 0.46883656509695265\n",
            "Merged communities, new modularity: 0.4804362880886423\n",
            "Merged communities, new modularity: 0.4918628808864264\n",
            "Merged communities, new modularity: 0.5032894736842102\n",
            "Merged communities, new modularity: 0.5145429362880881\n",
            "Merged communities, new modularity: 0.5257963988919662\n",
            "Merged communities, new modularity: 0.5422437673130189\n",
            "Merged communities, new modularity: 0.5538434903047085\n",
            "Merged communities, new modularity: 0.5645775623268691\n",
            "Merged communities, new modularity: 0.5753116343490298\n",
            "Merged communities, new modularity: 0.5853531855955674\n",
            "Merged communities, new modularity: 0.5953947368421048\n",
            "Merged communities, new modularity: 0.6054362880886422\n",
            "Merged communities, new modularity: 0.6154778393351796\n",
            "Merged communities, new modularity: 0.625519390581717\n",
            "Merged communities, new modularity: 0.6353878116343485\n",
            "Merged communities, new modularity: 0.6450831024930742\n",
            "Merged communities, new modularity: 0.6525277008310237\n",
            "Merged communities, new modularity: 0.6594529085872564\n",
            "Merged communities, new modularity: 0.6646468144044313\n",
            "Merged communities, new modularity: 0.6691481994459826\n",
            "Merged communities, new modularity: 0.6734764542936279\n",
            "Merged communities, new modularity: 0.6760734072022144\n",
            "\n",
            "Final communities:\n",
            "Community 0: [np.int64(32524), np.int64(32536)]\n",
            "Community 1: [np.int64(32485), np.int64(32540)]\n",
            "Community 2: [np.int64(32414), np.int64(32426), np.int64(32503), np.int64(32521)]\n",
            "Community 3: [np.int64(32405), np.int64(32413), np.int64(32444), np.int64(32452), np.int64(32453), np.int64(32481)]\n",
            "Community 4: [np.int64(32402), np.int64(32421), np.int64(32422), np.int64(32476), np.int64(32522), np.int64(32529), np.int64(32545)]\n",
            "Community 5: [np.int64(32407), np.int64(32411), np.int64(32436), np.int64(32439), np.int64(32455), np.int64(32488), np.int64(32520), np.int64(32552)]\n",
            "Community 6: [np.int64(32406), np.int64(32428), np.int64(32443), np.int64(32448), np.int64(32459), np.int64(32460), np.int64(32464), np.int64(32466), np.int64(32473), np.int64(32484), np.int64(32491), np.int64(32498), np.int64(32526), np.int64(32544)]\n",
            "Community 7: [np.int64(32401), np.int64(32440), np.int64(32442), np.int64(32445), np.int64(32500), np.int64(32519), np.int64(32535), np.int64(32538), np.int64(32557), np.int64(32561)]\n",
            "Community 8: [np.int64(32393), np.int64(32415), np.int64(32425), np.int64(32441), np.int64(32449), np.int64(32451), np.int64(32457), np.int64(32472), np.int64(32482), np.int64(32490), np.int64(32547), np.int64(32556), np.int64(32559), np.int64(32560), np.int64(32564), np.int64(32565)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "# ---------- 1. Degree-based bully score  ----------\n",
        "def bully_score_degree(subg, weight=None):\n",
        "    in_d  = dict(subg.in_degree(weight=weight))   # # nominations received\n",
        "    out_d = dict(subg.out_degree(weight=weight))  # # nominations made\n",
        "    return {n: in_d[n] - out_d[n] for n in subg.nodes()}  # +ve ⇒ likely bully\n",
        "\n",
        "# ---------- 2. PageRank on the *reversed* graph ----------\n",
        "def bully_score_pagerank(subg, weight=None, alpha=0.85):\n",
        "    # Reverse edges so \"influential receivers\" of disrespect rank highest\n",
        "    return nx.pagerank(subg, alpha=alpha, weight=weight)\n",
        "\n",
        "# ---------- 3. Combine & pick top candidate ----------\n",
        "def combine_scores(deg_dict, pr_dict, w_deg=0.6, w_pr=0.4):\n",
        "    nodes = list(deg_dict.keys())\n",
        "    d_s   = minmax_scale([deg_dict[n] for n in nodes])\n",
        "    p_s   = minmax_scale([pr_dict[n]  for n in nodes])\n",
        "    return {n: w_deg*d_s[i] + w_pr*p_s[i] for i, n in enumerate(nodes)}\n",
        "\n",
        "def community_subgraphs(G, communities):\n",
        "    for cid, nodes in enumerate(communities):\n",
        "        yield cid, G.subgraph(nodes).copy()\n",
        "\n",
        "def bully_candidates(G_d, communities, weight=None):\n",
        "    results = {}\n",
        "    for cid, subg in community_subgraphs(G_d, communities):\n",
        "        deg_score = bully_score_degree(subg, weight)\n",
        "        pr_score  = bully_score_pagerank(subg, weight)\n",
        "        combo     = combine_scores(deg_score, pr_score)\n",
        "        bully     = max(combo, key=combo.get)              # top candidate\n",
        "        ranked    = sorted(combo.items(), key=lambda x: x[1], reverse=True)\n",
        "        results[cid] = {\"primary_bully\": bully, \"ranking\": ranked}\n",
        "    return results"
      ],
      "metadata": {
        "id": "T4g0T2yh8SDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bully_info  = bully_candidates(G, final_communities)\n",
        "\n",
        "for cid, info in bully_info.items():\n",
        "    print(f\"Community {cid}: primary bully → {info['primary_bully']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX6_FE3HF6_Y",
        "outputId": "b1e3882b-3113-4982-e5eb-07b561cc5634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Community 0: primary bully → 32536\n",
            "Community 1: primary bully → 32485\n",
            "Community 2: primary bully → 32414\n",
            "Community 3: primary bully → 32405\n",
            "Community 4: primary bully → 32422\n",
            "Community 5: primary bully → 32455\n",
            "Community 6: primary bully → 32466\n",
            "Community 7: primary bully → 32500\n",
            "Community 8: primary bully → 32441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "# `final_communities` is a list of sets\n",
        "# `bully_info` is a dict: {community_id: {\"primary_bully\": ID}}\n",
        "\n",
        "# 1. Create a reverse lookup from student to their community\n",
        "student_to_community = {}\n",
        "for cid, members in enumerate(final_communities):\n",
        "    for student in members:\n",
        "        student_to_community[student] = cid\n",
        "\n",
        "# 2. Extract all bullies\n",
        "bully_dict = {}\n",
        "for cid, info in bully_info.items():\n",
        "    primary_bully = info[\"primary_bully\"]\n",
        "    victims = [sid for sid in final_communities[cid] if sid != primary_bully]\n",
        "    bully_dict[primary_bully] = victims\n",
        "\n",
        "# 3. Victim subgraph (exclude all known bullies)\n",
        "all_victims = {sid for comm in final_communities for sid in comm}\n",
        "all_bullies = set(bully_dict.keys())\n",
        "victim_nodes = all_victims - all_bullies\n",
        "\n",
        "victim_graph = G.subgraph(victim_nodes).copy()"
      ],
      "metadata": {
        "id": "X7xzn2Uhn82l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPA Regression"
      ],
      "metadata": {
        "id": "o9EkXNxAoG_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import HeteroConv, GATConv\n",
        "from pathlib import Path\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 1. Load workbook & node table\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "file_path = \"/content/Student Survey - Jan.xlsx\"\n",
        "sheets = pd.read_excel(file_path, sheet_name=None)\n",
        "df_nodes = (sheets[\"participants\"]\n",
        "            .merge(sheets[\"responses\"], on=\"Participant-ID\", how=\"left\",\n",
        "                   suffixes=(\"\", \"_resp\")))\n",
        "df_nodes = df_nodes.dropna(subset=[\"Perc_Academic\"])      # keep only labelled\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 2. Tabular preprocessing ➜ numpy feature matrix\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "# 2-a.  Label-aware normalisation  (z-score within House)\n",
        "df_nodes[\"House\"] = df_nodes[\"House\"].astype(\"category\")\n",
        "mu  = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"mean\")\n",
        "std = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"std\").clip(lower=1e-6)\n",
        "y_raw = df_nodes[\"Perc_Academic\"].to_numpy(dtype=\"float32\")        # keep raw\n",
        "y     = ((y_raw - mu) / std).to_numpy(dtype=\"float32\")             # scaled\n",
        "\n",
        "# 2-b.  *now* drop the target so it isn’t used as an input feature\n",
        "df_nodes = df_nodes.drop(columns=[\"Perc_Academic\"])\n",
        "df_nodes = df_nodes.dropna(axis=1, how=\"all\")             # drop empty columns\n",
        "\n",
        "num_cols = df_nodes.select_dtypes([\"int64\", \"float64\"]).columns\n",
        "cat_cols = df_nodes.select_dtypes([\"object\", \"category\", \"bool\"]).columns\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"std\", StandardScaler())\n",
        "    ]), num_cols),\n",
        "\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        # ↓ set sparse_output=False (sklearn ≥1.2) or sparse=False (≤1.1)\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "    ]), cat_cols)\n",
        "])\n",
        "\n",
        "X = pre.fit_transform(df_nodes).astype(\"float32\")   # now a NumPy ndarray\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 3. Build HeteroData with **six relations + reverse edges**\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "pid_arr = df_nodes[\"Participant-ID\"].to_numpy()\n",
        "pid2idx = {pid: i for i, pid in enumerate(pid_arr)}\n",
        "\n",
        "data = HeteroData()\n",
        "data[\"student\"].x = torch.from_numpy(X)\n",
        "data[\"student\"].y = torch.from_numpy(y)\n",
        "\n",
        "edge_sheets = {\n",
        "    \"friends\"     : \"net_0_Friends\",\n",
        "    \"influential\" : \"net_1_Influential\",\n",
        "    \"feedback\"    : \"net_2_Feedback\",\n",
        "    \"moretime\"    : \"net_3_MoreTime\",\n",
        "    \"advice\"      : \"net_4_Advice\",\n",
        "    \"disrespect\"  : \"net_5_Disrespect\"\n",
        "}\n",
        "\n",
        "for rel, sheet_name in edge_sheets.items():\n",
        "    df_e = sheets[sheet_name][[\"Source\", \"Target\"]].dropna()\n",
        "    mask = df_e[\"Source\"].isin(pid2idx) & df_e[\"Target\"].isin(pid2idx)\n",
        "    src = df_e.loc[mask, \"Source\"].map(pid2idx).to_numpy()\n",
        "    dst = df_e.loc[mask, \"Target\"].map(pid2idx).to_numpy()\n",
        "    if len(src) == 0:             # skip empty relations\n",
        "        continue\n",
        "    ei = torch.tensor([src, dst], dtype=torch.long)\n",
        "    data[\"student\", rel, \"student\"].edge_index = ei\n",
        "    # add explicit reverse relation to aid message flow\n",
        "    data[\"student\", f\"{rel}_rev\", \"student\"].edge_index = ei.flip(0)\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 4. Masks\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "seed = 42\n",
        "bins = pd.qcut(y, q=4, labels=False, duplicates=\"drop\")\n",
        "sss  = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=seed)\n",
        "train_idx, tmp_idx = next(sss.split(np.arange(len(y)), bins))\n",
        "\n",
        "# split the remaining 30 % in half (stratified)\n",
        "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
        "val_idx, test_idx = next(sss2.split(tmp_idx, bins[tmp_idx]))\n",
        "\n",
        "# build boolean masks\n",
        "for name, idx_arr in [(\"train_mask\", train_idx),\n",
        "                      (\"val_mask\",   val_idx),\n",
        "                      (\"test_mask\",  test_idx)]:\n",
        "    mask = torch.zeros(data[\"student\"].num_nodes, dtype=torch.bool)\n",
        "    mask[idx_arr] = True\n",
        "    data[\"student\"][name] = mask\n",
        "\n",
        "# ╒══════════════════════════════════════════════════════════════════════╕\n",
        "# 5. 2-layer Relational GAT\n",
        "# ╘══════════════════════════════════════════════════════════════════════╛\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class RGAT(torch.nn.Module):\n",
        "    def __init__(self, metadata, in_dim, hid=64, heads=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.lin_in = torch.nn.Linear(in_dim, hid)\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(2):\n",
        "            conv_dict = {\n",
        "                et: GATConv(\n",
        "                    (-1, -1),\n",
        "                    32,\n",
        "                    heads=heads,\n",
        "                    concat=True,\n",
        "                    dropout=0.2,\n",
        "                    add_self_loops=False         # ← keep this\n",
        "                    # edge_dropout=0.2  ← remove / comment out\n",
        "                    )\n",
        "                for et in metadata[1]\n",
        "}\n",
        "            self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "\n",
        "        self.lin_out = torch.nn.Linear(32 * heads, 1)   # 32×3 → 1\n",
        "        self.dp = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x_dict = {\"student\": torch.relu(self.lin_in(data[\"student\"].x))}\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, data.edge_index_dict)\n",
        "            x_dict = {k: torch.relu(v) for k, v in x_dict.items()}\n",
        "            x_dict = {k: self.dp(v)    for k, v in x_dict.items()}\n",
        "        return self.lin_out(x_dict[\"student\"]).squeeze()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RGAT(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "data = data.to(device)\n",
        "opt  = torch.optim.Adam(model.parameters(), lr=1.0e-3, weight_decay=5e-4)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "#  (everything up to HeteroData stays the same, except use y not y_raw)\n",
        "\n",
        "# ===================================================================\n",
        "#  B.  tiny grid search: depth ∈ {2,3}, heads ∈ {2–6}, dropout ∈ {0–0.4}\n",
        "# ===================================================================\n",
        "hyper_grid = {\n",
        "    \"depth\":   [2, 3],\n",
        "    \"heads\":   [2, 3, 4, 5, 6],\n",
        "    \"dropout\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "}\n",
        "best_val = float(\"inf\")\n",
        "best_cfg, best_state = None, None\n",
        "\n",
        "for depth in hyper_grid[\"depth\"]:\n",
        "    for heads in hyper_grid[\"heads\"]:\n",
        "        for dp in hyper_grid[\"dropout\"]:\n",
        "            torch.manual_seed(seed)           # reproducible per run\n",
        "            np.random.seed(seed)\n",
        "\n",
        "            # -- define RGAT with variable depth / heads / dropout ----\n",
        "            class RGAT(torch.nn.Module):\n",
        "                def __init__(self, metadata, in_dim):\n",
        "                    super().__init__()\n",
        "                    self.lin_in = torch.nn.Linear(in_dim, 64)\n",
        "                    self.convs = torch.nn.ModuleList()\n",
        "                    for _ in range(depth):\n",
        "                        conv_dict = {\n",
        "                            et: GATConv((-1, -1), 32,\n",
        "                                        heads=heads, concat=True,\n",
        "                                        dropout=dp, add_self_loops=False)\n",
        "                            for et in metadata[1]\n",
        "                        }\n",
        "                        self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "                    self.lin_out = torch.nn.Linear(32 * heads, 1)\n",
        "                    self.dp = torch.nn.Dropout(dp)\n",
        "\n",
        "                def forward(self, d):\n",
        "                    x = {\"student\": torch.relu(self.lin_in(d[\"student\"].x))}\n",
        "                    for conv in self.convs:\n",
        "                        x = conv(x, d.edge_index_dict)\n",
        "                        x = {k: torch.relu(v) for k, v in x.items()}\n",
        "                        x = {k: self.dp(v)    for k, v in x.items()}\n",
        "                    return self.lin_out(x[\"student\"]).squeeze()\n",
        "\n",
        "            model = RGAT(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "            opt   = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "            sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\",\n",
        "                                                               factor=0.5, patience=10)\n",
        "            best_rmse, wait = float(\"inf\"), 0\n",
        "            for epoch in range(1, 401):\n",
        "                model.train(); opt.zero_grad()\n",
        "                out  = model(data)\n",
        "                loss = loss_fn(out[data[\"student\"].train_mask],\n",
        "                               data[\"student\"].y[data[\"student\"].train_mask])\n",
        "                loss.backward(); opt.step()\n",
        "\n",
        "                # validation\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    v_pred = model(data)[data[\"student\"].val_mask].cpu()\n",
        "                v_rmse = np.sqrt(mean_squared_error(\n",
        "                    data[\"student\"].y[data[\"student\"].val_mask].cpu(), v_pred))\n",
        "                sched.step(v_rmse)\n",
        "\n",
        "                if v_rmse + 1e-3 < best_rmse:\n",
        "                    best_rmse, wait = v_rmse, 0\n",
        "                    best_state = model.state_dict()\n",
        "                else:\n",
        "                    wait += 1\n",
        "                if wait >= 30:               # early stop\n",
        "                    break\n",
        "\n",
        "            # keep global best\n",
        "            if best_rmse < best_val:\n",
        "                best_val, best_cfg = best_rmse, (depth, heads, dp)\n",
        "                torch.save(best_state, \"rgat_best_overall.pt\")\n",
        "\n",
        "print(f\"Best config depth={best_cfg[0]} heads={best_cfg[1]} dropout={best_cfg[2]:.1f}\"\n",
        "      f\"  |  val-RMSE={best_val:5.2f}\")\n",
        "\n",
        "# ===================================================================\n",
        "#  C.  final test metrics on best model\n",
        "# ===================================================================\n",
        "# ── rebuild model with the winning hyper-params ─────────────────────\n",
        "best_depth, best_heads, best_dp = best_cfg\n",
        "class RGAT_Best(torch.nn.Module):\n",
        "    def __init__(self, metadata, in_dim):\n",
        "        super().__init__()\n",
        "        self.lin_in = torch.nn.Linear(in_dim, 64)\n",
        "        self.convs  = torch.nn.ModuleList()\n",
        "        for _ in range(best_depth):\n",
        "            conv_dict = {\n",
        "                et: GATConv((-1, -1), 32,\n",
        "                            heads=best_heads, concat=True,\n",
        "                            dropout=best_dp, add_self_loops=False)\n",
        "                for et in metadata[1]\n",
        "            }\n",
        "            self.convs.append(HeteroConv(conv_dict, aggr=\"mean\"))\n",
        "        self.lin_out = torch.nn.Linear(32 * best_heads, 1)\n",
        "        self.dp = torch.nn.Dropout(best_dp)\n",
        "\n",
        "    def forward(self, d):\n",
        "        x = {\"student\": torch.relu(self.lin_in(d[\"student\"].x))}\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, d.edge_index_dict)\n",
        "            x = {k: torch.relu(v) for k, v in x.items()}\n",
        "            x = {k: self.dp(v)    for k, v in x.items()}\n",
        "        return self.lin_out(x[\"student\"]).squeeze()\n",
        "\n",
        "model = RGAT_Best(data.metadata(), in_dim=data[\"student\"].x.size(1)).to(device)\n",
        "model.load_state_dict(torch.load(\"rgat_best_overall.pt\"), strict=False)\n",
        "model.eval()\n",
        "\n",
        "# ── test inference ───────────────────────────────────────────────────\n",
        "with torch.no_grad():\n",
        "    y_hat_scaled = model(data).cpu().numpy()\n",
        "\n",
        "# un-scale back to raw GPA units\n",
        "y_hat = y_hat_scaled * std.to_numpy() + mu.to_numpy()\n",
        "\n",
        "test_mask = data[\"student\"].test_mask.cpu().numpy()\n",
        "mae  = mean_absolute_error(y_raw[test_mask], y_hat[test_mask])\n",
        "rmse = np.sqrt(mean_squared_error(y_raw[test_mask], y_hat[test_mask]))\n",
        "r2   = r2_score(y_raw[test_mask], y_hat[test_mask])\n",
        "\n",
        "print(\"\\n=== RGAT  (grid-tuned, label-normalised) ===\")\n",
        "print(f\"MAE : {mae:5.2f}\")\n",
        "print(f\"RMSE: {rmse:5.2f}\")\n",
        "print(f\"R²  : {r2:5.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi5sHvmQHouM",
        "outputId": "68ac2a65-930e-42dd-99a1-24782fd32249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-b763de18607f>:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  mu  = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"mean\")\n",
            "<ipython-input-12-b763de18607f>:28: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  std = df_nodes.groupby(\"House\")[\"Perc_Academic\"].transform(\"std\").clip(lower=1e-6)\n",
            "<ipython-input-12-b763de18607f>:80: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  ei = torch.tensor([src, dst], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best config depth=2 heads=2 dropout=0.0  |  val-RMSE= 0.52\n",
            "\n",
            "=== RGAT  (grid-tuned, label-normalised) ===\n",
            "MAE :  2.35\n",
            "RMSE:  7.81\n",
            "R²  :  0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1wTIERqq0MY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}